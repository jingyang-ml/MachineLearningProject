# MachineLearningProject
# Part 1. Develop the neural network on Pima Indians Diabetes Database using Keras
- Train and evaluate a sequential neural network model using Keras.

- Build the network and plot the training, validation loss, the training and validation accuracy.

- Use a trained network to generate predictions on new data.

- Change the number of hidden layers and hidden units of the network and use different loss functions and activation functions and optimizers. Critically discuss how these changes affect validation and test accuracy.

# Part 2. Logistic regression classification
- Generate a training set with two classes, where each instance has a single attribute x. The positive class is generated by a Gaussian distribution of zero mean and unit standard deviation while the negative class is generated by a Gaussian distribution of mean 3 and unit standard deviation. Each class has 1000 instances.

- Build a Logistic regression classifier on the above training set, using the Logistic Regression implementation of sklearn starting with the default parameters, and experimenting with different parameter values, to obtain better performance, if possible.

- Obtain the class probability estimates using the best classifier on a test set constructed in the same way as the training set. Plot the histogram of the probability estimates, using appropriate binning.

# Part 3. Naive Bayes
- Generate a training set with two classes, where each instance has two attributes x1,x2 The positive class is generated by a Gaussian distribution of mean equal to (0, 0) and unit standard deviation whereas the negative class is generated by a Gaussian distribution of mean equal to (5,5) and unit standard deviation. Each class has 1000 instances.

- Build a Gaussian Naive Bayes classifier on the training set using sklearn.

# Part 4. Unsupervised learning and the EM algorithm

- Cluster the mouse dataset using the k-Means clustering algorithm. The variability of the resulting clusters as a function on different initializations.

- Cluster the mouse dataset using the EM algorithm. Experiment with parameter settings. The variability of the resulting clusters as a function of different initializations.
